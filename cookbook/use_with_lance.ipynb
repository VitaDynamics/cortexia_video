{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e6dc2d",
   "metadata": {},
   "source": [
    "# Use Cortexia with Lance Dataset\n",
    "\n",
    "Example: Use Cortexia with a Lance table.\n",
    "\n",
    "This example shows how to:\n",
    "- Read images stored as bytes from a Lance dataset column\n",
    "- Run features: Caption, Listing\n",
    "- Use Listing tags as prompts for Detection, then run Segmentation\n",
    "- Save annotated results to a new Lance table (or Parquet fallback)\n",
    "\n",
    "Assumptions:\n",
    "- The Lance dataset at `dummys/lance_data/all_in_one.lance` exists.\n",
    "- Image bytes are stored in the `camera_left` column (e.g., JPEG/PNG bytes).\n",
    "- The table has no annotations; other columns (video/frame ids) are optional.\n",
    "\n",
    "If your columns differ, set the env vars or change the defaults below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e29015",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deps \n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import io\n",
    "import json\n",
    "import datetime\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import pyarrow as pa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20238327",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HOME\"]=\"/vita-vepfs-data/fileset1/model/heng.li/huggingface\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make local package importable when running from cookbook/\n",
    "parent_path = str(Path.cwd().parent)\n",
    "if parent_path not in sys.path:\n",
    "    sys.path.append(parent_path)\n",
    "REPO_ROOT = parent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189f1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cotexia related thing \n",
    "import cortexia\n",
    "from cortexia.data.models.video import VideoFramePacket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Config\n",
    "# ----------------------------------------------------------------------------\n",
    "_repo_path = Path(REPO_ROOT)  # convert str to Path for safe joining\n",
    "\n",
    "DATASET_PATH = os.environ.get(\n",
    "    \"LANCE_DATASET\",\n",
    "    str(_repo_path / \"dummys\" / \"lance_data\" / \"all_in_one.lance\")\n",
    ")\n",
    "\n",
    "# Column names (customize as needed)\n",
    "IMAGE_COL = os.environ.get(\"LANCE_IMAGE_COL\", \"camera_left\")\n",
    "VIDEO_ID_COL = os.environ.get(\"LANCE_VIDEO_ID_COL\", None)   # e.g., \"video_id\" if present\n",
    "FRAME_NUM_COL = os.environ.get(\"LANCE_FRAME_NUM_COL\", None) # e.g., \"frame_number\" if present\n",
    "TIMESTAMP_COL = os.environ.get(\"LANCE_TIMESTAMP_COL\", None) # optional ms/seconds; default to index/30\n",
    "\n",
    "# Output path for annotated table\n",
    "OUTPUT_LANCE = os.environ.get(\n",
    "    \"LANCE_OUTPUT\",\n",
    "    str(_repo_path / \"dummys\" / \"lance_data\" / \"all_in_one_annotated.lance\")\n",
    ")\n",
    "OUTPUT_PARQUET = os.environ.get(\n",
    "    \"PARQUET_OUTPUT\",\n",
    "    str(_repo_path / \"dummys\" / \"lance_data\" / \"all_in_one_annotated.parquet\")\n",
    ")\n",
    "# Limit rows for demo (e.g., 8). Use 0 or unset to disable limiting.\n",
    "ROW_LIMIT = int(os.environ.get(\"LANCE_ROW_LIMIT\", \"8\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf644ff7",
   "metadata": {},
   "source": [
    "## Helpers to work with lance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ec613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_lance_table(dataset_path: str) -> pa.Table:\n",
    "    \"\"\"Load the entire Lance dataset into a PyArrow Table.\n",
    "\n",
    "    For simplicity of the cookbook example we load all rows. For large datasets,\n",
    "    adapt to stream batches or filter rows.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import lance\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"Lance Python package is required for this example. Install 'lance'.\"\n",
    "        ) from e\n",
    "\n",
    "    ds = lance.dataset(dataset_path)\n",
    "    # Convert to Arrow table (small demo dataset assumed)\n",
    "    tbl = ds.to_table()\n",
    "    return tbl\n",
    "\n",
    "\n",
    "def decode_image_from_bytes(b: bytes) -> np.ndarray:\n",
    "    \"\"\"Decode image bytes (e.g., JPEG/PNG) into an RGB numpy array.\"\"\"\n",
    "    with Image.open(io.BytesIO(b)) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        return np.array(im)\n",
    "\n",
    "\n",
    "def build_video_frame_packet(row: pa.Table, row_idx: int) -> VideoFramePacket:\n",
    "    \"\"\"Construct a VideoFramePacket from a 1-row Arrow table slice.\"\"\"\n",
    "    # Image\n",
    "    img_val = row[IMAGE_COL][0]\n",
    "    if hasattr(img_val, \"as_py\"):\n",
    "        img_val = img_val.as_py()\n",
    "    frame_np = decode_image_from_bytes(img_val)\n",
    "\n",
    "    # Video/frame/timestamp\n",
    "    if VIDEO_ID_COL and VIDEO_ID_COL in row.column_names:\n",
    "        vid = str(row[VIDEO_ID_COL][0])\n",
    "    else:\n",
    "        vid = \"lance_demo\"\n",
    "\n",
    "    if FRAME_NUM_COL and FRAME_NUM_COL in row.column_names:\n",
    "        frame_no = int(row[FRAME_NUM_COL][0])\n",
    "    else:\n",
    "        frame_no = int(row_idx)\n",
    "\n",
    "    if TIMESTAMP_COL and TIMESTAMP_COL in row.column_names:\n",
    "        ts_val = row[TIMESTAMP_COL][0]\n",
    "        if hasattr(ts_val, \"as_py\"):\n",
    "            ts_val = ts_val.as_py()\n",
    "        # Interpret as seconds if float, ms if int\n",
    "        if isinstance(ts_val, float):\n",
    "            ts = datetime.timedelta(seconds=ts_val)\n",
    "        elif isinstance(ts_val, int):\n",
    "            ts = datetime.timedelta(milliseconds=ts_val)\n",
    "        else:\n",
    "            ts = datetime.timedelta(seconds=frame_no / 30.0)\n",
    "    else:\n",
    "        ts = datetime.timedelta(seconds=frame_no / 30.0)\n",
    "\n",
    "    return VideoFramePacket(\n",
    "        frame_data=frame_np,\n",
    "        frame_number=frame_no,\n",
    "        timestamp=ts,\n",
    "        source_video_id=vid,\n",
    "        additional_metadata={},\n",
    "    )\n",
    "\n",
    "\n",
    "def make_loader(table: pa.Table):\n",
    "    \"\"\"Create a BatchProcessor-compatible loader over a fixed Arrow table.\"\"\"\n",
    "    def load_func(indices: List[int]) -> List[VideoFramePacket]:\n",
    "        # Take a subset table by row indices and convert to packets\n",
    "        sub = table.take(pa.array(indices))\n",
    "        frames: List[VideoFramePacket] = []\n",
    "        for pos, row_idx in enumerate(indices):\n",
    "            one = sub.slice(pos, 1)\n",
    "            frames.append(build_video_frame_packet(one, row_idx))\n",
    "        return frames\n",
    "\n",
    "    return load_func\n",
    "\n",
    "def results_to_struct_array(results):\n",
    "    if not results:\n",
    "        return pa.array([], type=pa.null())\n",
    "    first_struct = results[0].to_pyarrow_struct()\n",
    "    struct_type = first_struct.type\n",
    "    names = struct_type.names\n",
    "    dicts = []\n",
    "    for r in results:\n",
    "        s = r.to_pyarrow_struct()\n",
    "        scalar = s[0]\n",
    "        row = {}\n",
    "        for name in names:\n",
    "            try:\n",
    "                val = scalar[name]\n",
    "                row[name] = val.as_py() if val is not None else None\n",
    "            except KeyError:\n",
    "                row[name] = None\n",
    "        dicts.append(row)\n",
    "    return pa.array(dicts, type=struct_type)\n",
    "\n",
    "\n",
    "def limit_table(table: pa.Table, limit: int | None) -> pa.Table:\n",
    "    \"\"\"Return a slice of the table limited to `limit` rows (if > 0).\"\"\"\n",
    "    try:\n",
    "        if limit is None or int(limit) <= 0:\n",
    "            return table\n",
    "        limit = min(int(limit), len(table))\n",
    "        return table.slice(0, limit)\n",
    "    except Exception:\n",
    "        return table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd3382",
   "metadata": {},
   "source": [
    "## Create Features and get Lance Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Lance table:\", DATASET_PATH)\n",
    "table = load_lance_table(DATASET_PATH)\n",
    "# We Limit Table for demo runs\n",
    "table = limit_table(table, ROW_LIMIT)\n",
    "schema_cols = set(table.column_names)\n",
    "if IMAGE_COL not in schema_cols:\n",
    "    raise ValueError(f\"Column '{IMAGE_COL}' not found. Available: {sorted(schema_cols)}\")\n",
    "\n",
    "n_rows = len(table)\n",
    "print(f\"Rows: {n_rows}; image column: '{IMAGE_COL}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e9c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortexia.list_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices are row numbers\n",
    "indices = list(range(n_rows))\n",
    "load_func = make_loader(table)\n",
    "\n",
    "# Features\n",
    "caption = cortexia.create_feature(\"caption\")\n",
    "listing = cortexia.create_feature(\"listing\")\n",
    "detection = cortexia.create_feature(\"detection\")\n",
    "segmentation = cortexia.create_feature(\"segmentation\")\n",
    "\n",
    "# Materialize frames once for chaining and attachment\n",
    "frames = load_func(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25668092",
   "metadata": {},
   "source": [
    "**Why do we use add_annotation_result** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6a684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cortexia.data.io.batch_processor import BatchProcessor\n",
    "print(\"Running Caption via BatchProcessor and attaching to frames...\")\n",
    "frames_map = {idx: frames[idx] for idx in indices}\n",
    "bp = BatchProcessor(batch_size=4)\n",
    "bp.load_indices(indices)\n",
    "\n",
    "def bp_load(batch_indices: List[int]) -> List[VideoFramePacket]:\n",
    "    return [frames_map[i] for i in batch_indices]\n",
    "\n",
    "def bp_infer(fr_batch: List[VideoFramePacket], batch_indices: List[int]):\n",
    "    return caption.process_batch(fr_batch)\n",
    "\n",
    "def bp_save(idx: int, result):\n",
    "    frames_map[idx].add_annotation_result(result)\n",
    "\n",
    "# Process in batches and attach directly using save_func\n",
    "_ = bp.process_batch(load_func=bp_load, inference_func=bp_infer, save_func=bp_save, filter_func=None)\n",
    "\n",
    "# Collect attached caption results back from frames for later writing\n",
    "cap_results = []\n",
    "for f in frames:\n",
    "    if f.annotations and 'CaptionResult' in f.annotations:\n",
    "        cap_results.append(f.annotations['CaptionResult'])\n",
    "    else:\n",
    "        from cortexia.data.models.result.caption_result import CaptionResult\n",
    "        cap_results.append(CaptionResult(caption=\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95201d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Listing (BatchProcessor chain; attach + set prompts for detection)\n",
    "print(\"Running Listing via BatchProcessor and attaching to frames...\")\n",
    "list_results_map = {}\n",
    "bp2 = BatchProcessor(batch_size=4)\n",
    "bp2.load_indices(indices)\n",
    "\n",
    "def bp2_load(batch_indices: List[int]) -> List[VideoFramePacket]:\n",
    "    return [frames_map[i] for i in batch_indices]\n",
    "\n",
    "def bp2_infer(fr_batch: List[VideoFramePacket], batch_indices: List[int]):\n",
    "    return listing.process_batch(fr_batch)\n",
    "\n",
    "def bp2_save(idx: int, result):\n",
    "    f = frames_map[idx]\n",
    "    f.add_annotation_result(result)\n",
    "    # Also provide prompts for detection via metadata\n",
    "    f.additional_metadata[\"lister_results\"] = list(getattr(result, 'tags', []) or [])\n",
    "    list_results_map[idx] = result\n",
    "\n",
    "_ = bp2.process_batch(load_func=bp2_load, inference_func=bp2_infer, save_func=bp2_save, filter_func=None)\n",
    "list_results = [list_results_map[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf8366",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_results[0].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Detection\n",
    "print(\"Running Detection (prompted by Listing tags) and attaching...\")\n",
    "det_results = detection.process_batch(frames)\n",
    "for f, r in zip(frames, det_results):\n",
    "    f.add_annotation_result(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_results[0].detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3aec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Segmentation\n",
    "print(\"Running Segmentation (using Detection boxes) and attaching...\")\n",
    "seg_results = segmentation.process_batch(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e77a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seg_results[0].segmentations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1639c5b",
   "metadata": {},
   "source": [
    "**Lets check some examples** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa155c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(min(2, n_rows)):\n",
    "    print(f\"Row {i} -> caption: {cap_results[i].caption!r}\")\n",
    "    print(f\"Row {i} -> tags: {list_results[i].tags}\")\n",
    "    # Handle new DetectionResult format with multiple detections\n",
    "    if det_results[i].has_detections:\n",
    "        # Show first detection as example\n",
    "        first_det = det_results[i].detections[0]\n",
    "        print(\n",
    "            f\"Row {i} -> det: count={det_results[i].count}, first: label={first_det.label!r}, score={first_det.score:.3f}, box={first_det.box.xyxy}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Row {i} -> det: count=0, no detections\")\n",
    "    # Handle new SegmentationResult format with multiple segmentations\n",
    "    if seg_results[i].has_segmentations:\n",
    "        # Show first segmentation as example\n",
    "        first_seg = seg_results[i].segmentations[0]\n",
    "        print(\n",
    "            f\"Row {i} -> seg: count={seg_results[i].count}, first: label={first_seg.label!r}, area={first_seg.area}, mask.shape={first_seg.mask.shape}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Row {i} -> seg: count=0, no segmentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d034f",
   "metadata": {},
   "source": [
    "**Lets write it into a table with annotation result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce69bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_caption_struct = results_to_struct_array(cap_results)\n",
    "col_tags_struct = results_to_struct_array(list_results)\n",
    "col_det_struct = results_to_struct_array(det_results)\n",
    "col_seg_struct = results_to_struct_array(seg_results)\n",
    "\n",
    "annotated = table\n",
    "annotated = annotated.append_column(\"cortexia_caption\", col_caption_struct)\n",
    "annotated = annotated.append_column(\"cortexia_tags\", col_tags_struct)\n",
    "annotated = annotated.append_column(\"cortexia_detection\", col_det_struct)\n",
    "annotated = annotated.append_column(\"cortexia_segmentation\", col_seg_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d6893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lance\n",
    "    out = Path(OUTPUT_LANCE)\n",
    "    out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # Overwrite destination if exists by writing a fresh dataset\n",
    "    if out.exists():\n",
    "        # Best-effort cleanup; Lance manages versions but this is a demo\n",
    "        import shutil\n",
    "        shutil.rmtree(out, ignore_errors=True)\n",
    "    lance.write_dataset(annotated, str(out))\n",
    "    print(f\"Annotated Lance dataset written to: {out}\")\n",
    "    wrote = True\n",
    "except Exception as e:\n",
    "    print(f\"Lance write failed or unavailable: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a quick preview for this table\n",
    "def preview_rows(tbl: pa.Table, k: int = 3):\n",
    "    print(\"Previewing first\", min(k, len(tbl)), \"rows (selected columns):\")\n",
    "    cols_to_show = [\n",
    "        c for c in [\n",
    "            VIDEO_ID_COL or None,\n",
    "            FRAME_NUM_COL or None,\n",
    "            \"cortexia_caption\",\n",
    "            \"cortexia_tags\",\n",
    "            \"cortexia_detection\",\n",
    "            \"cortexia_segmentation\",\n",
    "        ] if c and c in tbl.column_names\n",
    "    ]\n",
    "    for i in range(min(k, len(tbl))):\n",
    "        row = tbl.slice(i, 1)\n",
    "        summary = {}\n",
    "        for c in cols_to_show:\n",
    "            cell = row[c][0]\n",
    "            try:\n",
    "                summary[c] = cell.as_py()\n",
    "            except Exception:\n",
    "                summary[c] = str(cell)\n",
    "        print(f\"Row {i}:\", summary)\n",
    "\n",
    "preview_rows(annotated, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d47d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
